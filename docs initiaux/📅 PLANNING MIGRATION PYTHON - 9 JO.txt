ðŸ“… PLANNING MIGRATION PYTHON - 9 JOURS (6h/jour)
JOUR 1 (J1) - Setup Infrastructure & Structure (6h)
Matin (3h)

 CrÃ©er repo Python vide (ou branche)
 Setup virtualenv: python -m venv venv
 Installer dÃ©pendances core dans requirements.txt:

  fastapi==0.104.1
  python-dotenv==1.0.0
  supabase==2.3.5
  openai==1.3.0
  httpx==0.25.0
  pydantic==2.5.0
  pytest==7.4.3
  python-multipart==0.0.6

 CrÃ©er structure dossiers:

  backend/
  â”œâ”€â”€ app/
  â”‚   â”œâ”€â”€ __init__.py
  â”‚   â”œâ”€â”€ main.py                 # FastAPI app
  â”‚   â”œâ”€â”€ config.py               # Env variables
  â”‚   â”œâ”€â”€ models/
  â”‚   â”‚   â”œâ”€â”€ __init__.py
  â”‚   â”‚   â”œâ”€â”€ user_data.py        # Pydantic models
  â”‚   â”‚   â””â”€â”€ report_output.py
  â”‚   â”œâ”€â”€ services/
  â”‚   â”‚   â”œâ”€â”€ __init__.py
  â”‚   â”‚   â”œâ”€â”€ colorimetry.py      # Service colorimÃ©trie
  â”‚   â”‚   â”œâ”€â”€ morphology.py       # Service morphologie
  â”‚   â”‚   â”œâ”€â”€ styling.py          # Service profil style
  â”‚   â”‚   â”œâ”€â”€ visuals.py          # Service visuels
  â”‚   â”‚   â”œâ”€â”€ products.py         # Service produits
  â”‚   â”‚   â””â”€â”€ pdf_generation.py   # Service PDF
  â”‚   â”œâ”€â”€ utils/
  â”‚   â”‚   â”œâ”€â”€ __init__.py
  â”‚   â”‚   â”œâ”€â”€ supabase_client.py  # Client Supabase
  â”‚   â”‚   â”œâ”€â”€ openai_client.py    # Client OpenAI + retry
  â”‚   â”‚   â””â”€â”€ validators.py       # Validation donnÃ©es
  â”‚   â””â”€â”€ prompts/
  â”‚       â”œâ”€â”€ __init__.py
  â”‚       â”œâ”€â”€ colorimetry_prompt.py
  â”‚       â”œâ”€â”€ morphology_prompt.py
  â”‚       â””â”€â”€ styling_prompt.py
  â”œâ”€â”€ tests/
  â”‚   â”œâ”€â”€ __init__.py
  â”‚   â”œâ”€â”€ test_colorimetry.py
  â”‚   â””â”€â”€ test_integration.py
  â”œâ”€â”€ .env.example
  â”œâ”€â”€ requirements.txt
  â”œâ”€â”€ docker-compose.yml
  â””â”€â”€ README.md

 Copier fichiers SYNTHESE_COMPLETE_MIGRATION_PYTHON.md et prompts complets dans le repo

AprÃ¨s-midi (3h)

 CrÃ©er app/config.py avec variables env:

python  SUPABASE_URL = os.getenv("SUPABASE_URL")
  SUPABASE_KEY = os.getenv("SUPABASE_KEY")
  OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
  PDFMONKEY_API_KEY = os.getenv("PDFMONKEY_API_KEY")
  STRIPE_SECRET_KEY = os.getenv("STRIPE_SECRET_KEY")

 CrÃ©er app/main.py FastAPI minimal:

python  from fastapi import FastAPI
  from fastapi.middleware.cors import CORSMiddleware
  
  app = FastAPI()
  app.add_middleware(CORSMiddleware, ...)
  
  @app.post("/api/webhook/stripe")
  async def handle_payment(payload: dict):
      return {"status": "ok"}

 Initialiser .env.example avec toutes les variables
 Tester: uvicorn app.main:app --reload
 Git commit: "feat: initial project structure"

Checkpoint: FastAPI dÃ©marre sur http://localhost:8000

JOUR 2 (J2) - Clients & Utils (6h)
Matin (3h)

 CrÃ©er app/utils/supabase_client.py:

python  from supabase import create_client
  
  class SupabaseClient:
      def __init__(self):
          self.client = create_client(SUPABASE_URL, SUPABASE_KEY)
      
      async def get_user_profile(self, user_id: str):
          response = self.client.table("user_profiles").select("*").eq("id", user_id).single()
          return response.data
      
      async def query(self, table, filters):
          # MÃ©thode gÃ©nÃ©rique
          pass

 CrÃ©er app/utils/openai_client.py avec retry logic:

python  from openai import AsyncOpenAI
  import tenacity
  
  class OpenAIClient:
      def __init__(self):
          self.client = AsyncOpenAI(api_key=OPENAI_API_KEY)
      
      @tenacity.retry(stop=tenacity.stop_after_attempt(3))
      async def analyze_image(self, image_urls, prompt, model="gpt-4-vision"):
          # Appel OpenAI avec retry
          pass

 CrÃ©er app/models/user_data.py:

python  from pydantic import BaseModel
  from typing import List
  
  class UserProfileInput(BaseModel):
      user_id: str
      face_photo_url: str
      body_photo_url: str
      measurements: dict
      # ... autres champs
AprÃ¨s-midi (3h)

 Tester clients: crÃ©er tests/test_clients.py

Test connexion Supabase
Test appel OpenAI (avec faux token pour vÃ©rifier format)
Mock donnÃ©es


 CrÃ©er app/models/report_output.py (Pydantic models pour outputs):

python  class ColorimetryResult(BaseModel):
      season: str
      palette_personnalisee: List[dict]
      guide_maquillage: dict
  
  class MorphologyResult(BaseModel):
      silhouette_type: str
      recommendations: dict
      body_analysis: dict

 Git commit: "feat: clients and models setup"

Checkpoint: Clients testÃ©s, modÃ¨les dÃ©finis

JOUR 3 (J3) - Service ColorimÃ©trie (6h)
Matin (3h)

 CrÃ©er app/prompts/colorimetry_prompt.py avec prompt complet de la synthÃ¨se
 CrÃ©er app/services/colorimetry.py:

python  from app.utils.openai_client import OpenAIClient
  from app.models.report_output import ColorimetryResult
  import json
  
  class ColorimetryService:
      def __init__(self):
          self.openai = OpenAIClient()
      
      async def analyze(self, user_data):
          # 1. Construire prompt avec donnÃ©es utilisateur
          prompt = build_colorimetry_prompt(user_data)
          
          # 2. Appel OpenAI Vision
          response = await self.openai.analyze_image(
              image_urls=[user_data["face_photo_url"]],
              prompt=prompt,
              model="gpt-4-vision"
          )
          
          # 3. Parser JSON response
          result = json.loads(response)
          
          # 4. Valider avec Pydantic
          return ColorimetryResult(**result)
AprÃ¨s-midi (3h)

 Tests unitaires tests/test_colorimetry.py:

Mock OpenAI response
VÃ©rifier parsing JSON
VÃ©rifier structure ColorimetryResult
Tester edge cases (erreur OpenAI, JSON invalide)


 IntÃ©grer endpoint FastAPI:

python  @app.post("/api/test/colorimetry")
  async def test_colorimetry(user_data: UserProfileInput):
      service = ColorimetryService()
      result = await service.analyze(user_data)
      return result

 Git commit: "feat: colorimetry service with tests"

Checkpoint: Service colorimÃ©trie fonctionnel, testable via endpoint

JOUR 4 (J4) - Service Morphologie (6h)
Matin (3h)

 CrÃ©er app/prompts/morphology_prompt.py avec prompt de la synthÃ¨se
 CrÃ©er app/services/morphology.py (similaire Ã  colorimÃ©trie):

python  class MorphologyService:
      async def analyze(self, user_data):
          # Image body entiÃ¨re + mesures
          response = await self.openai.analyze_image(
              image_urls=[user_data["body_photo_url"]],
              prompt=build_morphology_prompt(user_data),
              model="gpt-4-vision"
          )
          result = json.loads(response)
          return MorphologyResult(**result)
AprÃ¨s-midi (3h)

 Tests: tests/test_morphology.py
 Endpoint FastAPI /api/test/morphology
 Important: VÃ©rifier que les cut keys dans le JSON correspondent exactement aux noms dans la table visuels Supabase

Ex: encolure_en_v, robe_empire, top_fluide, etc.
Ajuster prompt OpenAI si besoin pour normaliser


 Git commit: "feat: morphology service"

Checkpoint: Morphologie testÃ©e, JSON contient les bonnes clÃ©s

JOUR 5 (J5) - Service Profil Style (6h)
Matin (3h)

 CrÃ©er app/prompts/styling_prompt.py avec prompt complet
 CrÃ©er app/services/styling.py:

python  class StylingService:
      async def generate(self, colorimetry_result, morphology_result, user_data):
          # Combine les 2 rÃ©sultats + prefs utilisateur
          # ChatGPT (pas vision, juste texte)
          response = await self.openai.call(
              model="gpt-4",
              prompt=build_styling_prompt(colorimetry_result, morphology_result)
          )
          result = json.loads(response)
          return StylingResult(**result)
AprÃ¨s-midi (3h)

 Tests: tests/test_styling.py
 Endpoint /api/test/styling (prend colorimetry + morphology en input)
 Important: VÃ©rifier que les 10 formules mix&match sont bien complÃ¨tes (bug connu: formules 7-10 Ã©taient coupÃ©es)

Ajuster token limit dans prompt si nÃ©cessaire


 Git commit: "feat: styling service"

Checkpoint: Les 3 services IA fonctionnent indÃ©pendamment

JOUR 6 (J6) - Service Visuels (6h)
Matin (3h)

 CrÃ©er app/services/visuals.py:

python  class VisualsService:
      def __init__(self, supabase_client):
          self.supabase = supabase_client
      
      async def fetch_for_recommendations(self, morphology_result):
          """
          Pour chaque catÃ©gorie (hauts, bas, robes, etc.),
          rÃ©cupÃ¨re les visuels pÃ©dagogiques correspondants
          """
          visuals_by_category = {}
          
          for category in ["hauts", "bas", "robes", "vestes", "maillots", "accessoires"]:
              if category not in morphology_result["recommendations"]:
                  continue
              
              visuals_by_category[category] = {
                  "a_privilegier": [],
                  "a_eviter": []
              }
              
              # Boucle sur chaque recommandation
              for rec in morphology_result["recommendations"][category]["a_privilegier"]:
                  cut_key = rec["cut"]  # Ex: "encolure_en_v"
                  
                  # Query Supabase table "visuels"
                  visual = await self.supabase.query(
                      table="visuels",
                      filters={
                          "category": category,
                          "cut_key": cut_key
                      }
                  )
                  
                  if visual:
                      visuals_by_category[category]["a_privilegier"].append({
                          **rec,
                          "image_url": visual["image_url"],
                          "visual_id": visual["id"]
                      })
          
          return visuals_by_category
AprÃ¨s-midi (3h)

 Tests: tests/test_visuals.py

Mock Supabase responses
VÃ©rifier mapping cut_key â†” image_url
VÃ©rifier fallback si visuel manquant


 Endpoint /api/test/visuals (prend morphology result en input)
 CRITIQUE: VÃ©rifier dans ta BD Supabase que la table visuels a:

Colonne category (hauts, bas, robes, vestes, maillots, accessoires)
Colonne cut_key (encolure_en_v, robe_empire, etc.) â†’ NORMALISÃ‰
Colonne image_url
Si manquant â†’ ajouter migration Supabase


 Git commit: "feat: visuals service with dynamic mapping"

Checkpoint: Visuels mappÃ©s dynamiquement par morphologie

JOUR 7 (J7) - Service Produits & Parallelization (6h)
Matin (3h)

 CrÃ©er app/services/products.py:

python  class ProductsService:
      def __init__(self, supabase_client):
          self.supabase = supabase_client
      
      async def fetch_recommendations(self, category, colorimetry, morphology):
          """
          RÃ©cupÃ¨re produits filtrÃ©s par:
          - CatÃ©gorie (hauts, bas, robes, etc.)
          - Tags colorimÃ©trie (season, warm/cold)
          - Tags morphologie (body_type)
          """
          # Query Edge Function ou direct Supabase
          products = await self.supabase.query(
              table="Products place des tendances",
              filters={
                  "category_primary": category,
                  "colorimetry_season": colorimetry["season"],
                  "morphology_tags": [morphology["silhouette_type"]]
              },
              limit=20
          )
          return products
AprÃ¨s-midi (3h)

 CrÃ©er main endpoint /api/webhook/stripe avec parallelization:

python  import asyncio
  
  @app.post("/api/webhook/stripe")
  async def handle_payment(payload: dict):
      user_data = await supabase.get_user(payload["user_id"])
      
      # PARALLELISER: colorimÃ©trie + morphologie
      colorimetry_task = colorimetry_service.analyze(user_data)
      morphology_task = morphology_service.analyze(user_data)
      
      colorimetry, morphology = await asyncio.gather(
          colorimetry_task,
          morphology_task
      )
      
      # Puis: profil style (sÃ©quentiel, dÃ©pend des 2)
      styling = await styling_service.generate(colorimetry, morphology, user_data)
      
      # PARALLELISER: visuels + 5 catÃ©gories produits
      visuals_task = visuals_service.fetch_for_recommendations(morphology)
      products_tasks = [
          products_service.fetch_recommendations("hauts", colorimetry, morphology),
          products_service.fetch_recommendations("bas", colorimetry, morphology),
          products_service.fetch_recommendations("robes", colorimetry, morphology),
          products_service.fetch_recommendations("chaussures", colorimetry, morphology),
          products_service.fetch_recommendations("vestes", colorimetry, morphology),
      ]
      
      visuals, *products_lists = await asyncio.gather(
          visuals_task,
          *products_tasks
      )
      
      return {
          "colorimetry": colorimetry,
          "morphology": morphology,
          "styling": styling,
          "visuals": visuals,
          "products": products_lists
      }

 Tests intÃ©gration: tests/test_integration.py
 Git commit: "feat: products service and parallelization"

Checkpoint: 2 tÃ¢ches parallÃ¨les colorimetry+morphology, puis products en parallÃ¨le

JOUR 8 (J8) - PDF Generation avec PDFMonkey (6h)
Matin (3h)

 CrÃ©er app/services/pdf_generation.py:

python  import httpx
  
  class PDFGenerationService:
      def __init__(self, pdfmonkey_api_key):
          self.api_key = pdfmonkey_api_key
          self.pdfmonkey_url = "https://api.pdfmonkey.io/api/v1"
      
      async def generate_report_pdf(self, report_data):
          """
          Envoie donnÃ©es Ã  PDFMonkey
          PDFMonkey utilise template HTML stockÃ© chez eux
          """
          payload = {
              "document": {
                  "document_template_id": os.getenv("PDFMONKEY_TEMPLATE_ID"),
                  "status": "success",
                  "file_format": "pdf",
                  "meta": {
                      "user_id": report_data["user_id"],
                      "created_at": datetime.now().isoformat()
                  },
                  "payload": report_data  # Toutes les donnÃ©es du rapport
              }
          }
          
          async with httpx.AsyncClient() as client:
              response = await client.post(
                  f"{self.pdfmonkey_url}/documents",
                  json=payload,
                  headers={
                      "Authorization": f"Bearer {self.api_key}",
                      "Content-Type": "application/json"
                  }
              )
              result = response.json()
              return result["document"]["download_url"]
AprÃ¨s-midi (3h)

 PRÃ‰ALABLE: Obtenir de toi le template PDFMonkey actuel (HTML Mustache)

Convertir variables Mustache â†’ noms de champs du payload Python
CrÃ©er mapping: template_variables.json


 Tests: tests/test_pdf_generation.py (mock PDFMonkey API)
 IntÃ©grer dans endpoint Stripe:

python  pdf_url = await pdf_service.generate_report_pdf({
      "user_name": user_data["first_name"],
      "colorimetry": colorimetry.dict(),
      "morphology": morphology.dict(),
      "styling": styling.dict(),
      "visuals": visuals,
      "products": products_lists
  })

 Git commit: "feat: PDF generation with PDFMonkey integration"

Checkpoint: PDFs gÃ©nÃ©rÃ©es via PDFMonkey, tÃ©lÃ©chargeables

JOUR 9 (J9) - Integration, Tests & Deployment (6h)
Matin (3h)

 Test end-to-end complet: tests/test_e2e.py

Webhook Stripe â†’ PDF gÃ©nÃ©rÃ©
Mesurer temps exÃ©cution (objectif: <20s)
VÃ©rifier structure JSON Ã  chaque Ã©tape


 CrÃ©er docker-compose.yml pour dev local:

yaml  version: '3.8'
  services:
    api:
      build: .
      ports:
        - "8000:8000"
      environment:
        - SUPABASE_URL=${SUPABASE_URL}
        - OPENAI_API_KEY=${OPENAI_API_KEY}
      volumes:
        - .:/app

 CrÃ©er .env.example complet avec toutes les variables

AprÃ¨s-midi (3h)

 DÃ©ploiement test sur Railway/Render:

CrÃ©er Procfile ou railway.json
Test webhook Stripe â†’ endpoint production
VÃ©rifier logs


 CrÃ©er README.md avec:

Setup local (virtualenv, requirements.txt)
Variables d'env requises
Commandes tests
Architecture diagram (copie du projet)
Checklist dÃ©ploiement


 Git commit: "feat: E2E tests, Docker setup, deployment config"

Checkpoint: Tout fonctionne end-to-end, dÃ©ployable

ðŸŽ¯ Ce qu'il faut prÃ©parer AVANT de commencer
Je te demande de prÃ©parer pour moi (J0 - avant de commencer):

URL Edge Function get-product-recommendations OU template de ce qu'elle retourne actuellement (JSON example)
Template PDFMonkey HTML complet avec variables Mustache â†’ je le convertis pour Python
Screenshot/export de la table visuels Supabase (colonnes exact, exemple de lignes)
Credentials:

SUPABASE_URL
SUPABASE_KEY (anon ou service role)
OPENAI_API_KEY
PDFMONKEY_API_KEY
STRIPE_SECRET_KEY




ðŸ“Š Timeline rÃ©sumÃ©e
JourFocusLivrableJ1Setup + StructureRepo prÃªt, FastAPI dÃ©marreJ2Clients + ModelsSupabase/OpenAI testÃ©sJ3ColorimÃ©trieService + testsJ4MorphologieService + testsJ5Profil StyleService + testsJ6VisuelsMapping dynamique OKJ7Produits + ParallelizationWebhook endpointJ8PDF + PDFMonkeyPDFs gÃ©nÃ©rÃ©esJ9E2E + DeployProduction-ready
Total: 9 jours Ã— 6h = 54h de dev â†’ ~3x plus rapide que Make.com