"""
Morphology Service v5.2 - FINAL CORRIG√â
‚úÖ Accepte la vraie structure retourn√©e par Part 1
‚úÖ G√©n√®re highlights et minimizes EN INTERNE √† partir de body_parts_to_highlight/minimize
‚úÖ Fusionne avec onboarding morphology_goals
‚úÖ G√©n√®re explanation et tips enrichis personnalis√©s
"""

import json
import re
from app.utils.openai_client import openai_client
from app.utils.openai_call_tracker import call_tracker
from app.prompts.morphology_part1_prompt import MORPHOLOGY_PART1_SYSTEM_PROMPT, MORPHOLOGY_PART1_USER_PROMPT
from app.prompts.morphology_part2_prompt import MORPHOLOGY_PART2_SYSTEM_PROMPT, MORPHOLOGY_PART2_USER_PROMPT
from app.prompts.morphology_part3_prompt import MORPHOLOGY_PART3_SYSTEM_PROMPT, MORPHOLOGY_PART3_USER_PROMPT


class MorphologyService:
    def __init__(self):
        self.openai = openai_client
        print(f"‚úÖ MorphologyService loaded. Has _generate_default_recommendations: {hasattr(self, '_generate_default_recommendations')}")

    
    @staticmethod
    def safe_format(template: str, **kwargs) -> str:
        """Format un template en ignorant les cl√©s manquantes - ULTRA ROBUSTE"""
        # Utiliser une classe defaultdict pour retourner vide string pour ANY missing key
        class SafeDict(dict):
            def __missing__(self, key):
                return ""  # Retourner "" pour toute cl√© manquante au lieu de lever KeyError
        
        safe_dict = SafeDict(kwargs)
        try:
            return template.format_map(safe_dict)
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur format_map: {str(e)}")
            return template
    
    @staticmethod
    def clean_json_string(content: str) -> str:
        """Nettoie une r√©ponse JSON pour √©viter les erreurs de parsing"""
        content = re.sub(r'^```json\s*', '', content)
        content = re.sub(r'\s*```$', '', content)
        content = content.replace('\x00', '')
        content = re.sub(r'\\([√©√®√™√´√†√¢√§√π√ª√º√¥√∂√Æ√Ø≈ì√¶])', r'\1', content)
        return content
    @staticmethod
    def sanitize_json_multiline_strings(raw: str) -> str:
        """
        Rend un JSON beaucoup plus parseable en supprimant les retours √† la ligne
        ET tabulations √† l'int√©rieur des strings JSON (entre guillemets).
        Objectif: √©viter les JSON invalides quand OpenAI casse une string sur 2 lignes.
        """
        if not raw:
            return raw

        out = []
        in_string = False
        escape = False

        for ch in raw:
            if in_string:
                if escape:
                    escape = False
                    out.append(ch)
                    continue

                if ch == "\\":
                    escape = True
                    out.append(ch)
                    continue

                # Interdire retours ligne / tabs DANS une string JSON
                if ch in ("\n", "\r", "\t"):
                    out.append(" ")
                    continue

                if ch == '"':
                    in_string = False

                out.append(ch)
            else:
                if ch == '"':
                    in_string = True
                out.append(ch)

        return "".join(out)
 
    @staticmethod
    def merge_body_parts(onboarding_parts: list, openai_parts: list) -> list:
        """Fusionne les parties du corps en d√©duplicant"""
        if not openai_parts:
            openai_parts = []
        if not onboarding_parts:
            onboarding_parts = []
        
        onboarding_normalized = {part.lower().strip(): part for part in onboarding_parts}
        openai_normalized = {part.lower().strip(): part for part in openai_parts}
        
        merged = {}
        for norm, orig in onboarding_normalized.items():
            merged[norm] = orig
        for norm, orig in openai_normalized.items():
            if norm not in merged:
                merged[norm] = orig
        
        return list(merged.values())
    
    async def analyze(self, user_data: dict) -> dict:
        """Analyse morphologie EN 2 APPELS S√âQUENTIELS"""
        print("\n" + "="*80)
        print("üí™ PHASE MORPHOLOGIE v5.2 (2 appels + g√©n√©ration highlights/minimizes)")
        print("="*80)
        
        body_photo_url = user_data.get("body_photo_url")
        if not body_photo_url:
            print("‚ùå Pas de photo du corps fournie")
            return {}
        
        # R√©cup√©rer les morphology_goals du onboarding
        print("\nüìã R√âCUP√âRATION MORPHOLOGY GOALS DU ONBOARDING")
        profile = user_data.get("profile", {})
        onboarding_data = profile.get("onboarding_data", {})
        morphology_goals = onboarding_data.get("morphology_goals", {})
        
        onboarding_highlight_parts = morphology_goals.get("body_parts_to_highlight", [])
        onboarding_minimize_parts = morphology_goals.get("body_parts_to_minimize", [])
        
        print(f"   ‚Ä¢ √Ä valoriser (onboarding): {onboarding_highlight_parts}")
        print(f"   ‚Ä¢ √Ä minimiser (onboarding): {onboarding_minimize_parts}")
        
        part1_result = {}
        part2_result = {}
        
        try:
            # ========================================================================
            # APPEL 1/2: MORPHOLOGY PART 1 - SILHOUETTE (VISION)
            # ========================================================================
            print("\n" + "‚ñà"*80)
            print("‚ñà APPEL 1/2: MORPHOLOGY PART 1 - SILHOUETTE + BODY ANALYSIS (VISION)")
            print("‚ñà"*80)
            
            print("\nüìã AVANT APPEL:")
            print("   ‚Ä¢ Type: OpenAI Vision API (gpt-4-turbo)")
            print("   ‚Ä¢ Max tokens: 800")
            
            self.openai.set_context("Morphology Part 1", "PART 1: Silhouette")
            self.openai.set_system_prompt(MORPHOLOGY_PART1_SYSTEM_PROMPT)
            
            user_prompt_part1 = self.safe_format(
                MORPHOLOGY_PART1_USER_PROMPT,
                body_photo_url=body_photo_url,
                shoulder_circumference=user_data.get("shoulder_circumference", 0),
                waist_circumference=user_data.get("waist_circumference", 0),
                hip_circumference=user_data.get("hip_circumference", 0),
                bust_circumference=user_data.get("bust_circumference", 0)
            )
            
            print("\nü§ñ APPEL OPENAI EN COURS...")
            response_part1 = await self.openai.analyze_image(
                image_urls=[body_photo_url],
                prompt=user_prompt_part1,
                model="gpt-4-turbo",
                max_tokens=800
            )
            print("‚úÖ R√âPONSE RE√áUE")
            
            content_part1 = response_part1.get("content", "")
            
            print("\nüìù R√âPONSE BRUTE COMPL√àTE (Part 1) - {} chars:".format(len(content_part1)))
            print("="*80)
            print(content_part1[:1000] if len(content_part1) > 1000 else content_part1)
            print("="*80)
            
            # PARSING PART 1
            print("\nüîç PARSING JSON PART 1:")
            content_part1_clean = self.clean_json_string(content_part1)
            
            try:
                part1_result = json.loads(content_part1_clean)
                print("   ‚úÖ Parsing r√©ussi!")
                print("      ‚Ä¢ Silhouette: {}".format(part1_result.get('silhouette_type', 'N/A')))
                
            except json.JSONDecodeError as e:
                print(f"   ‚ùå Erreur parsing JSON: {str(e)}")
                json_match = re.search(r'\{.*\}', content_part1_clean, re.DOTALL)
                if json_match:
                    try:
                        part1_result = json.loads(json_match.group())
                        print("   ‚úÖ Extraction JSON r√©ussie!")
                    except:
                        print("   ‚ùå Extraction aussi √©chou√©e")
                        part1_result = {}
                else:
                    part1_result = {}
            
            # ========================================================================
            # APPEL 2/2: MORPHOLOGY PART 2 - RECOMMANDATIONS (TEXT)
            # ========================================================================
            print("\n" + "‚ñà"*80)
            print("‚ñà APPEL 2/2: MORPHOLOGY PART 2 - RECOMMANDATIONS STYLING (TEXT)")
            print("‚ñà"*80)
            
            if part1_result and part1_result.get("silhouette_type"):
                silhouette = part1_result.get("silhouette_type")
                styling_objectives = part1_result.get("styling_objectives", [])
            else:
                silhouette = "O"
                styling_objectives = ["Optimal"]
            
            objectives_str = ", ".join(styling_objectives) if styling_objectives else "Optimize"
            
            print("\nüìã AVANT APPEL:")
            print("   ‚Ä¢ Silhouette: {}".format(silhouette))
            
            self.openai.set_context("Morphology Part 2", "PART 2: Recommandations")
            self.openai.set_system_prompt(MORPHOLOGY_PART2_SYSTEM_PROMPT)
            
            user_prompt_part2 = self.safe_format(
                MORPHOLOGY_PART2_USER_PROMPT,
                silhouette_type=silhouette,
                styling_objectives=objectives_str
            )
            
            print("\nü§ñ APPEL OPENAI EN COURS...")
            response_part2 = await self.openai.call_chat(
                prompt=user_prompt_part2,
                model="gpt-4-turbo",
                max_tokens=2500  # ‚úÖ Augment√© de 800 ‚Üí 2000 pour √©viter la troncature
            )
            print("‚úÖ R√âPONSE RE√áUE")
            
            content_part2 = response_part2.get("content", "")
            
            print("\nüìù R√âPONSE BRUTE COMPL√àTE (Part 2) - {} chars:".format(len(content_part2)))
            print("="*80)
            print(content_part2[:1000] if len(content_part2) > 1000 else content_part2)
            print("="*80)
            
            # PARSING PART 2 - ULTRA-ROBUSTE
            # PARSING PART 2 - ULTRA-ROBUSTE + LOGS
            print("\nüîç PARSING JSON PART 2:")
            content_part2_clean = self.clean_json_string(content_part2)
            content_part2_clean = self.sanitize_json_multiline_strings(content_part2_clean)

            try:
                part2_result = json.loads(content_part2_clean)
                print("   ‚úÖ Parsing r√©ussi!")

            except json.JSONDecodeError as e:
                print("   ‚ö†Ô∏è JSON invalide ‚Üí tentative correction OpenAI")
                print(f"   ‚ùå JSONDecodeError: line={e.lineno} col={e.colno} pos={e.pos}")
                excerpt = content_part2_clean[max(0, e.pos-180): e.pos+180]
                print(f"   üîé Extrait autour erreur: {excerpt}")
                print(f"   üìè Longueur r√©ponse (clean): {len(content_part2_clean)} chars")
                print(f"   üß© Fin de r√©ponse (200 derniers chars): {content_part2_clean[-200:]}")

                try:
                    part2_result = await self.force_valid_json(
                        content_part2_clean,
                        context="Morphology Part 2"
                    )
                    print("   ‚úÖ JSON corrig√© par OpenAI")

                except Exception as fix_e:
                    print(f"   ‚ùå Correction √©chou√©e ‚Üí fallback ({str(fix_e)})")

                    fallback_fn = getattr(self, "_generate_default_recommendations", None)
                    if callable(fallback_fn):
                        part2_result = fallback_fn(silhouette)
                    else:
                        print("   ‚ùå Fallback impossible: _generate_default_recommendations introuvable ‚Üí fallback minimal")
                        part2_result = {"recommendations": {}}



            # ========================================================================
            # MORPHOLOGY PART 3 - D√âTAILS DE STYLING (MATIERES + MOTIFS + PI√àGES)
            # ========================================================================
            print("\n" + "="*80)
            print("üîç MORPHOLOGIE PART 3 - D√âTAILS DE STYLING")
            print("="*80)

            print("\nüìã AVANT APPEL:")
            print("   ‚Ä¢ Silhouette: {}".format(silhouette))
            print("   ‚Ä¢ Type: OpenAI Chat API")
            print("   ‚Ä¢ Max tokens: 1800")

            self.openai.set_context("Morphology Part 3", "PART 3: D√©tails Styling")
            self.openai.set_system_prompt(MORPHOLOGY_PART3_SYSTEM_PROMPT)

            # Pr√©parer le user prompt Part 3
            styling_objectives_str = ", ".join(styling_objectives) if styling_objectives else "Optimal"
            body_parts_highlight = part1_result.get("body_parts_to_highlight", [])
            body_parts_minimize = part1_result.get("body_parts_to_minimize", [])

            highlight_str = ", ".join(body_parts_highlight) if body_parts_highlight else "G√©n√©ral"
            minimize_str = ", ".join(body_parts_minimize) if body_parts_minimize else "G√©n√©ral"

            user_prompt_part3 = self.safe_format(
                MORPHOLOGY_PART3_USER_PROMPT,
                silhouette_type=silhouette,
                styling_objectives=styling_objectives_str,
                body_parts_to_highlight=highlight_str,
                body_parts_to_minimize=minimize_str
            )

            print("\nü§ñ APPEL OPENAI EN COURS...")
            response_part3 = await self.openai.call_chat(
                prompt=user_prompt_part3,
                model="gpt-4-turbo",
                max_tokens=2500  # ‚úÖ Pour g√©n√©rer les 7 pi√®ges
            )
            print("‚úÖ R√âPONSE RE√áUE")

            content_part3 = response_part3.get("content", "")

            print("\nüìù R√âPONSE BRUTE COMPL√àTE (Part 3) - {} chars:".format(len(content_part3)))
            print("="*80)
            print(content_part3[:1000] if len(content_part3) > 1000 else content_part3)
            print("="*80)

            # PARSING PART 3
            print("\nüîç PARSING JSON PART 3:")
            content_part3_clean = self.clean_json_string(content_part3)
            content_part3_clean = self.sanitize_json_multiline_strings(content_part3_clean)

            try:
                # 1) Tentative parsing direct
                part3_result = json.loads(content_part3_clean)
                print("   ‚úÖ Parsing r√©ussi!")

                # ‚úÖ Normalisation si le mod√®le a renvoy√© "recommendations" au lieu de "details"
                if isinstance(part3_result, dict) and "details" not in part3_result:
                    if "recommendations" in part3_result and isinstance(part3_result["recommendations"], dict):
                        part3_result["details"] = part3_result["recommendations"]


            except json.JSONDecodeError:
                print("   ‚ö†Ô∏è JSON invalide ‚Üí tentative extraction brute")

                # 2) Tentative extraction brute du JSON entre premi√®re { et derni√®re }
                start = content_part3_clean.find("{")
                end = content_part3_clean.rfind("}") + 1

                if start != -1 and end > start:
                    extracted = content_part3_clean[start:end]
                    extracted = self.sanitize_json_multiline_strings(extracted)
                    try:
                        part3_result = json.loads(extracted)
                        print("   ‚úÖ Extraction JSON r√©ussie!")
                    except json.JSONDecodeError:
                        print("   ‚ö†Ô∏è Extraction √©chou√©e ‚Üí tentative correction OpenAI")
                        try:
                            part3_result = await self.force_valid_json(
                                extracted,
                                context="Morphology Part 3"
                            )
                            print("   ‚úÖ JSON corrig√© par OpenAI")
                        except Exception:
                            print("   ‚ùå Correction √©chou√©e ‚Üí fallback")
                            part3_result = {"details": {}}
                else:
                    print("   ‚ö†Ô∏è Aucun bloc JSON d√©tect√© ‚Üí tentative correction OpenAI")
                    try:
                        part3_result = await self.force_valid_json(
                            content_part3_clean,
                            context="Morphology Part 3"
                        )
                        print("   ‚úÖ JSON corrig√© par OpenAI")
                    except Exception:
                        print("   ‚ùå Correction √©chou√©e ‚Üí fallback")
                        part3_result = {"details": {}}

            # ============================
            # NORMALISATION PART 3 (ANTI-VIDE)
            # ============================
            expected_cats = ["hauts", "bas", "robes", "vestes", "maillot_lingerie", "chaussures", "accessoires"]

            # Cas 1: cat√©gories √† la racine
            if isinstance(part3_result, dict) and "details" not in part3_result:
                if any(k in part3_result for k in expected_cats):
                    part3_result = {"details": {k: part3_result.get(k, {}) for k in expected_cats}}

                # Cas 2: bloc g√©n√©rique √† la racine
                elif any(k in part3_result for k in ["matieres", "motifs", "pieges"]):
                    generic_block = {
                        "matieres": part3_result.get("matieres", []),
                        "motifs": part3_result.get("motifs", {}),
                        "pieges": part3_result.get("pieges", [])
                    }
                    part3_result = {"details": {k: generic_block for k in expected_cats}}

            # S√©curiser la structure
            if not isinstance(part3_result, dict):
                part3_result = {"details": {}}

            if "details" not in part3_result or not isinstance(part3_result["details"], dict):
                part3_result["details"] = {}

            for cat in expected_cats:
                if cat not in part3_result["details"] or not isinstance(part3_result["details"][cat], dict):
                    part3_result["details"][cat] = {}
                part3_result["details"][cat].setdefault("matieres", [])
                part3_result["details"][cat].setdefault("motifs", {"recommandes": [], "a_eviter": []})
                part3_result["details"][cat].setdefault("pieges", [])

            details = part3_result.get("details", {})
            print("      ‚Ä¢ Cat√©gories trouv√©es: {}".format(list(details.keys())))

                
            # ========================================================================
            # FUSION ONBOARDING + OPENAI + G√âN√âRATION HIGHLIGHTS/MINIMIZES
            # ========================================================================
            print("\n" + "="*80)
            print("üîó FUSION ONBOARDING + OPENAI")
            print("="*80)
            
            # Part 1 retourne body_parts_to_highlight/minimize (listes simples)
            openai_highlight_parts = part1_result.get("body_parts_to_highlight", [])
            openai_minimize_parts = part1_result.get("body_parts_to_minimize", [])
            
            print("\n   OpenAI recommande:")
            print(f"   ‚Ä¢ √Ä valoriser: {openai_highlight_parts}")
            print(f"   ‚Ä¢ √Ä minimiser: {openai_minimize_parts}")
            
            # Fusionner les parties (d√©duplication)
            merged_highlight_parts = self.merge_body_parts(
                onboarding_highlight_parts,
                openai_highlight_parts
            )
            merged_minimize_parts = self.merge_body_parts(
                onboarding_minimize_parts,
                openai_minimize_parts
            )
            
            print("\n   Apr√®s fusion (union unique):")
            print(f"   ‚Ä¢ √Ä valoriser: {merged_highlight_parts}")
            print(f"   ‚Ä¢ √Ä minimiser: {merged_minimize_parts}")
            
            # Extraire silhouette_explanation comme explanation personnalis√©e
            silhouette_explanation = part1_result.get("silhouette_explanation", "")
            
            # V√âRIFIER SI OPENAI A D√âJ√Ä RETOURN√â highlights et minimizes
            print("\n‚úÖ V√âRIFICATION: OpenAI a-t-il fourni highlights/minimizes ?")
            openai_highlights = part1_result.get("highlights", {})
            openai_minimizes = part1_result.get("minimizes", {})
            
            has_openai_highlights = bool(openai_highlights and openai_highlights.get("announcement"))
            has_openai_minimizes = bool(openai_minimizes and openai_minimizes.get("announcement"))
            
            print(f"   ‚Ä¢ OpenAI highlights fournis: {has_openai_highlights}")
            print(f"   ‚Ä¢ OpenAI minimizes fournis: {has_openai_minimizes}")
            
            # Construire les donn√©es finales pour Page 8
            if has_openai_highlights:
                # Utiliser les donn√©es d'OpenAI directement (AVEC TIPS !)
                print("   ‚Üí Utilisation des donn√©es OpenAI pour highlights")
                tips_text = ""
                if openai_highlights.get("tips"):
                    tips_text = "\n\nASPECTS √Ä VALORISER (conseils):\n" + "\n".join([f"‚Ä¢ {tip}" for tip in openai_highlights.get("tips", [])])
                
                highlights_data = {
                    "announcement": openai_highlights.get("announcement", ""),
                    "explanation": openai_highlights.get("explanation", ""),
                    "tips": openai_highlights.get("tips", []),
                    "full_text": f"ANNONCE: {openai_highlights.get('announcement', '')}\n\nEXPLICATION: {openai_highlights.get('explanation', '')}{tips_text}"
                }
            else:
                # G√©n√©rer en interne (fallback)
                print("   ‚Üí G√©n√©ration interne des donn√©es pour highlights")
                highlights_data = self._format_highlights_for_page8(
                    parties=merged_highlight_parts,
                    silhouette_explanation=silhouette_explanation,
                    onboarding_parties=onboarding_highlight_parts,
                    openai_parties=openai_highlight_parts
                )
            
            if has_openai_minimizes:
                # Utiliser les donn√©es d'OpenAI directement (AVEC TIPS !)
                print("   ‚Üí Utilisation des donn√©es OpenAI pour minimizes")
                tips_text = ""
                if openai_minimizes.get("tips"):
                    tips_text = "\n\nASPECTS √Ä MINIMISER (conseils):\n" + "\n".join([f"‚Ä¢ {tip}" for tip in openai_minimizes.get("tips", [])])
                
                minimizes_data = {
                    "announcement": openai_minimizes.get("announcement", ""),
                    "explanation": openai_minimizes.get("explanation", ""),
                    "tips": openai_minimizes.get("tips", []),
                    "full_text": f"ANNONCE: {openai_minimizes.get('announcement', '')}\n\nEXPLICATION: {openai_minimizes.get('explanation', '')}{tips_text}"
                }
            else:
                # G√©n√©rer en interne (fallback)
                print("   ‚Üí G√©n√©ration interne des donn√©es pour minimizes")
                minimizes_data = self._format_minimizes_for_page8(
                    parties=merged_minimize_parts,
                    silhouette_explanation=silhouette_explanation,
                    onboarding_parties=onboarding_minimize_parts,
                    openai_parties=openai_minimize_parts
                )
            
            print("\n‚úÖ Highlights g√©n√©r√©s:")
            print(f"   ‚Ä¢ Parties: {merged_highlight_parts}")
            
            print("\n‚úÖ Minimizes g√©n√©r√©s:")
            print(f"   ‚Ä¢ Parties: {merged_minimize_parts}")
            
            
            # ========================================================================
            # FUSION PART 2 + PART 3 (Ajouter les matieres, motifs, pieges)
            # ========================================================================
            print("\n" + "="*80)
            print("üîó FUSION PART 2 + PART 3")
            print("="*80)

            recommendations_part2 = part2_result.get("recommendations", {})
            details_part3 = part3_result.get("details", {})

            # Fusionner les deux pour chaque cat√©gorie
            merged_recommendations = {}
            for category in ["hauts", "bas", "robes", "vestes", "maillot_lingerie", "chaussures", "accessoires"]:
                part2_cat = recommendations_part2.get(category, {})
                part3_cat = details_part3.get(category, {})
                
                merged = {
                    "introduction": part2_cat.get("introduction", ""),
                    "recommandes": part2_cat.get("recommandes", []),
                    "a_eviter": part2_cat.get("pieces_a_eviter", part2_cat.get("a_eviter", [])),
                    "matieres": part3_cat.get("matieres", part2_cat.get("matieres", "")),
                    "motifs": part3_cat.get("motifs", part2_cat.get("motifs", {})),
                    "pieges": part3_cat.get("pieges", []),  # ‚úÖ Des Part 3!
                    "visuels": []
                }
                
                # ======================================================
                # PATCH D ‚Äî INTRODUCTION M√âTIER PAR CAT√âGORIE (ANTI-VIDE)
                # ======================================================

                default_intros = {
                    "vestes": "Les vestes jouent un r√¥le cl√© dans la structuration de votre silhouette. Bien choisies, elles apportent de l‚Äô√©quilibre et de l‚Äôallure.",
                    "maillot_lingerie": "Les sous-v√™tements et maillots constituent la base invisible de votre silhouette. Leur coupe influence directement le rendu des v√™tements.",
                    "chaussures": "Les chaussures compl√®tent la silhouette et influencent la perception des proportions. Leur forme et leur structure sont d√©terminantes.",
                    "accessoires": "Les accessoires finalisent une tenue et orientent le regard. Bien proportionn√©s, ils renforcent l‚Äôharmonie globale."
                }

                if not merged.get("introduction") or len(merged["introduction"].strip()) < 40:
                    merged["introduction"] = default_intros.get(
                        category,
                        "Ces recommandations sont adapt√©es √† votre morphologie afin de cr√©er un ensemble coh√©rent."
                    )

                # ======================================================
                # FALLBACK ANTI-SECTIONS VIDES (MORPHOLOGY)
                # ======================================================

                if not merged["recommandes"]:
                    merged["recommandes"] = [
                        {
                            "cut_display": "Coupe adapt√©e √† votre silhouette",
                            "why": "Cette coupe permet d‚Äô√©quilibrer les volumes et de valoriser votre morphologie."
                        }
                    ]

                if not merged["a_eviter"]:
                    merged["a_eviter"] = [
                        {
                            "cut_display": "Coupe non structur√©e",
                            "why": "Elle risque de d√©s√©quilibrer visuellement la silhouette."
                        }
                    ]

                if not merged["pieges"]:
                    merged["pieges"] = [
                        "√âviter les volumes excessifs qui cassent l‚Äô√©quilibre naturel de la silhouette."
                    ]

                # ======================================================
                # PATCH C-2 ‚Äî DENSIT√â MINIMALE LISTES (ANTI-PAGES PAUVRES)
                # ======================================================

                def ensure_min_items(items, category, mode, min_items=4):
                    if len(items) >= min_items:
                        return items

                    fallback = {
                        "hauts": {
                            "recommandes": [
                                {"cut_display": "Haut structur√©", "why": "Structure le haut du corps"},
                                {"cut_display": "D√©tails verticaux", "why": "Allonge visuellement la silhouette"},
                            ],
                            "a_eviter": [
                                {"cut_display": "Haut trop ample", "why": "D√©s√©quilibre la carrure"},
                            ],
                        },
                        "bas": {
                            "recommandes": [
                                {"cut_display": "Coupe droite", "why": "√âquilibre les volumes"},
                                {"cut_display": "Taille bien positionn√©e", "why": "Structure la silhouette"},
                            ],
                            "a_eviter": [
                                {"cut_display": "Coupe trop moulante", "why": "Accentue les d√©s√©quilibres"},
                            ],
                        },
                        "robes": {
                            "recommandes": [
                                {"cut_display": "Robe structur√©e", "why": "Soutient les lignes naturelles"},
                                {"cut_display": "Taille marqu√©e", "why": "R√©√©quilibre les proportions"},
                            ],
                            "a_eviter": [
                                {"cut_display": "Robe informe", "why": "Efface la silhouette"},
                            ],
                        },
                        "vestes": {
                            "recommandes": [
                                {"cut_display": "Veste cintr√©e", "why": "Structure le buste"},
                                {"cut_display": "√âpaules d√©finies", "why": "Renforcent l‚Äô√©quilibre visuel"},
                            ],
                            "a_eviter": [
                                {"cut_display": "Veste trop large", "why": "Manque de tenue"},
                            ],
                        },
                    }

                    extras = fallback.get(category, {}).get(mode, [])
                    needed = max(0, min_items - len(items))
                    return items + extras[:needed]


                merged["recommandes"] = ensure_min_items(
                    merged["recommandes"], category, "recommandes"
                )

                merged["a_eviter"] = ensure_min_items(
                    merged["a_eviter"], category, "a_eviter"
                )

                # ======================================================
                # PATCH B ‚Äî DENSIFICATION RECOMMANDATIONS / A √âVITER
                # ======================================================

                def enrich_list(items, category, mode):
                    fallback = {
                        "hauts": {
                            "recommandes": [
                                {"cut_display": "Haut structur√©", "why": "Structure le haut du corps"},
                                {"cut_display": "D√©tails verticaux", "why": "Allonge visuellement la silhouette"},
                            ],
                            "a_eviter": [
                                {"cut_display": "Haut trop ample", "why": "Alourdit la carrure"},
                            ],
                        },
                        "robes": {
                            "recommandes": [
                                {"cut_display": "Robe fluide structur√©e", "why": "Suit les lignes naturelles"},
                                {"cut_display": "Taille marqu√©e", "why": "R√©√©quilibre les volumes"},
                            ],
                            "a_eviter": [
                                {"cut_display": "Robe droite rigide", "why": "Efface la silhouette"},
                            ],
                        },
                        "vestes": {
                            "recommandes": [
                                {"cut_display": "Veste cintr√©e", "why": "Structure le buste"},
                                {"cut_display": "√âpaule d√©finie", "why": "Renforce l‚Äô√©quilibre visuel"},
                            ],
                            "a_eviter": [
                                {"cut_display": "Veste informe", "why": "Manque de structure"},
                            ],
                        },
                    }

                    if len(items) >= 4:
                        return items

                    extra = fallback.get(category, {}).get(mode, [])
                    return items + extra[: max(0, 4 - len(items))]


                merged["recommandes"] = enrich_list(
                    merged["recommandes"], category, "recommandes"
                )

                merged["a_eviter"] = enrich_list(
                    merged["a_eviter"], category, "a_eviter"
                )

                # ======================================================
                # PATCH C2 ‚Äî FORMAT PDFMONKEY (RICH + STABLE)
                # Objectif:
                # - garder un JSON Part 3 "court" (listes de mots)
                # - enrichir en phrases c√¥t√© Python (z√©ro risque de JSON invalide d√ª aux longues phrases)
                # - rendre lisible: retours ligne + item en gras
                # ======================================================

                def _clean_txt(s: str) -> str:
                    if not isinstance(s, str):
                        return ""
                    return (
                        s.replace("\n", " ")
                         .replace("\r", " ")
                         .replace("\t", " ")
                         .replace("‚Ä¢", "")
                         .strip()
                    )

                def _dedupe_keep_order(items):
                    seen = set()
                    out = []
                    for it in items:
                        key = _clean_txt(str(it)).lower()
                        if not key or key in seen:
                            continue
                        seen.add(key)
                        out.append(_clean_txt(str(it)))
                    return out

                # Donn√©es morpho utiles pour contextualiser les phrases
                objectives_ctx = styling_objectives_str if isinstance(styling_objectives_str, str) else ""
                highlight_ctx = highlight_str if isinstance(highlight_str, str) else ""
                minimize_ctx = minimize_str if isinstance(minimize_str, str) else ""

                def _explain_material(mat: str, cat: str) -> str:
                    """
                    Phrase courte, orient√©e 'objectif morpho', sans d√©pendre d'OpenAI.
                    """
                    mat_l = mat.lower()
                    # heuristiques simples (suffisamment bonnes + stables)
                    if any(k in mat_l for k in ["cr√™pe", "viscose", "soie", "mousseline", "chiffon", "jersey", "fluide"]):
                        return f"apporte un tomb√© souple qui allonge visuellement et √©vite d‚Äôajouter du volume sur les zones √† minimiser ({minimize_ctx})."
                    if any(k in mat_l for k in ["tweed", "serg√©", "gabardine", "denim", "coton √©pais", "laine"]):
                        return f"donne de la tenue et structure la silhouette, utile pour soutenir les zones √† valoriser ({highlight_ctx}) et atteindre l‚Äôobjectif ({objectives_ctx})."
                    if any(k in mat_l for k in ["stretch", "√©lasthanne", "extensible"]):
                        return f"offre du confort tout en gardant une ligne nette, id√©al pour √©pouser sans comprimer et rester coh√©rent avec l‚Äôobjectif ({objectives_ctx})."
                    if any(k in mat_l for k in ["cuir", "su√©dine", "velours"]):
                        return f"ajoute de la mati√®re et du caract√®re sans √©paissir si la coupe reste structur√©e, ce qui aide √† √©quilibrer les proportions."
                    return f"reste coh√©rent avec l‚Äôobjectif morphologique ({objectives_ctx}) tout en gardant une silhouette lisible et harmonieuse."

                def _explain_pattern(pat: str, cat: str, mode: str) -> str:
                    pat_l = pat.lower()
                    if mode == "recommandes":
                        if any(k in pat_l for k in ["vertical", "rayure verticale", "lignes verticales"]):
                            return f"cr√©e une illusion d‚Äôallongement et guide le regard dans le sens de la hauteur, utile pour √©quilibrer la silhouette ({objectives_ctx})."
                        if any(k in pat_l for k in ["uni", "ton sur ton", "monochrome"]):
                            return f"rend la ligne plus lisible et plus √©l√©gante, ce qui affine visuellement et √©vite les ruptures sur les zones √† minimiser ({minimize_ctx})."
                        if any(k in pat_l for k in ["petit", "discret", "micro", "pois", "g√©om√©trique petit"]):
                            return f"apporte du style sans √©largir, en gardant une lecture l√©g√®re et proportionn√©e √† la morphologie."
                        if any(k in pat_l for k in ["textur√©", "relief", "subtil"]):
                            return f"ajoute du relief sans cr√©er de rupture forte, ce qui renforce l‚Äô√©quilibre global de la silhouette."
                        return f"reste proportionn√© √† la morphologie et aide √† mettre en valeur ({highlight_ctx}) sans surcharger ({minimize_ctx})."
                    else:
                        if any(k in pat_l for k in ["horizontal", "rayure horizontale", "bandes"]):
                            return f"√©largit visuellement et coupe la silhouette, ce qui peut accentuer les contrastes de volumes (√† √©viter sur {minimize_ctx})."
                        if any(k in pat_l for k in ["grand", "large", "oversize", "massif"]):
                            return f"attire fortement l‚Äôattention et amplifie la zone o√π il se place, donc √† √©viter sur les zones √† minimiser ({minimize_ctx})."
                        if any(k in pat_l for k in ["contrast√©", "flashy", "vif"]):
                            return f"cr√©e une rupture tr√®s marqu√©e et peut d√©s√©quilibrer l‚Äôensemble; mieux vaut limiter pour garder une silhouette harmonieuse."
                        return f"risque de cr√©er du volume visuel ou une rupture trop marqu√©e; √† limiter surtout si tu veux minimiser ({minimize_ctx})."

                def _to_html_lines(label: str, items: list, explain_fn, cat: str, mode: str = "") -> str:
                    """
                    Retourne un HTML compact (safe pour PDFMonkey) :
                    <strong>item</strong> : explication<br>
                    """
                    if not items:
                        return ""

                    items = _dedupe_keep_order(items)
                    lines = []
                    for it in items:
                        if not it:
                            continue
                        expl = explain_fn(it, cat) if mode == "" else explain_fn(it, cat, mode)
                        expl = _clean_txt(expl)
                        # IMPORTANT: √©viter les guillemets doubles dans l'HTML inject√©
                        lines.append(f"<strong>{it}</strong> : {expl}")
                    return "<br>".join(lines)

                # ---------------------------
                # MOTIFS: sources + fallback
                # ---------------------------
                motifs = merged.get("motifs", {})
                if isinstance(motifs, dict):
                    rec_list = motifs.get("recommandes", []) or []
                    avoid_list = motifs.get("a_eviter", []) or []
                elif isinstance(motifs, list):
                    rec_list = motifs
                    avoid_list = []
                else:
                    rec_list = []
                    avoid_list = []

                # fallback m√©tier si vide
                if not rec_list:
                    rec_list = [
                        "rayures verticales fines",
                        "uni",
                        "motifs discrets proportionn√©s"
                    ]
                if not avoid_list:
                    avoid_list = [
                        "rayures horizontales larges",
                        "motifs trop massifs",
                        "contrastes trop vifs"
                    ]

                # HTML final (avec explications)
                merged["motifs"] = {
                    "recommandes": _to_html_lines("recommandes", rec_list, _explain_pattern, category, mode="recommandes"),
                    "a_eviter": _to_html_lines("a_eviter", avoid_list, _explain_pattern, category, mode="a_eviter"),
                }

                # ---------------------------
                # MATIERES: sources + fallback
                # ---------------------------
                matieres = merged.get("matieres", [])
                if isinstance(matieres, str):
                    # si une string arrive malgr√© tout, on tente de la splitter grossi√®rement
                    matieres = [m.strip(" -‚Ä¢") for m in re.split(r"[‚Ä¢,\|;/]+", matieres) if m.strip()]
                elif not isinstance(matieres, list):
                    matieres = []

                if not matieres:
                    matieres = ["maille fine", "viscose fluide", "coton structur√©", "jersey doux"]

                merged["matieres"] = _to_html_lines("matieres", matieres, _explain_material, category)


                merged_recommendations[category] = merged
                pieges_count = len(merged.get('pieges', []))
                print(f"   ‚Ä¢ {category}: {pieges_count} pi√®ges")

            print("   ‚úÖ Fusion compl√©t√©e!")
            # ========================================================================
            # R√âSULTAT FINAL
            # ========================================================================
            print("\n" + "="*80)
            print("üì¶ R√âSULTAT FINAL")
            print("="*80)
            
            final_result = {
                "silhouette_type": part1_result.get("silhouette_type"),
                "silhouette_explanation": part1_result.get("silhouette_explanation"),
                "body_parts_to_highlight": part1_result.get("body_parts_to_highlight", []),
                "body_parts_to_minimize": part1_result.get("body_parts_to_minimize", []),
                "body_analysis": part1_result.get("body_analysis"),
                "styling_objectives": part1_result.get("styling_objectives", []),
                "bodyType": part1_result.get("silhouette_type"),
                "recommendations": merged_recommendations,  # ‚úÖ Avec Part 2 + Part 3!
                
                # ‚ú® DONN√âES POUR PAGE 8 (G√âN√âR√âES EN INTERNE)
                "highlights": highlights_data,
                "minimizes": minimizes_data,
            }
            
            print("‚úÖ Morphologie v5.2 g√©n√©r√©e avec succ√®s!")
            print("\n" + "="*80 + "\n")
            
            return final_result
            
        except Exception as e:
            print(f"\n‚ùå EXCEPTION: {str(e)}")
            call_tracker.log_error("Morphology", str(e))
            
            import traceback
            traceback.print_exc()
            
            return {
                "silhouette_type": part1_result.get("silhouette_type"),
                "silhouette_explanation": part1_result.get("silhouette_explanation"),
                "body_parts_to_highlight": part1_result.get("body_parts_to_highlight", []),
                "body_parts_to_minimize": part1_result.get("body_parts_to_minimize", []),
                "body_analysis": part1_result.get("body_analysis"),
                "styling_objectives": part1_result.get("styling_objectives", []),
                "bodyType": part1_result.get("silhouette_type"),
                "recommendations": merged_recommendations,  # ‚úÖ Avec Part 2 + Part 3!
            }
    
    def _format_highlights_for_page8(self, parties: list, silhouette_explanation: str,
                                     onboarding_parties: list, openai_parties: list) -> dict:
        """
        G√©n√®re les highlights pour Page 8
        Utilise silhouette_explanation comme base pour l'explanation
        """
        announcement = ", ".join(parties) if parties else "Votre silhouette"
        
        # L'explanation de base vient de silhouette_explanation
        explanation = silhouette_explanation
        
        # Enrichir avec les sources
        if onboarding_parties and openai_parties:
            explanation += f"\n\nCette analyse combine vos pr√©f√©rences (vous aviez s√©lectionn√©: {', '.join(onboarding_parties)}) avec nos recommandations morphologiques (nous sugg√©rons: {', '.join(openai_parties)})."
        elif onboarding_parties:
            explanation += f"\n\nVous aviez s√©lectionn√© ces parties √† valoriser: {', '.join(onboarding_parties)}."
        elif openai_parties:
            explanation += f"\n\nNous recommandons de valoriser: {', '.join(openai_parties)}."
        
        full_text = f"""ANNONCE: {announcement}

EXPLICATION: {explanation}"""
        
        return {
            "announcement": announcement,
            "explanation": explanation,
            "full_text": full_text
        }

    def _format_minimizes_for_page8(self, parties: list, silhouette_explanation: str,
                                    onboarding_parties: list, openai_parties: list) -> dict:
        """
        G√©n√®re les minimizes pour Page 8
        Utilise silhouette_explanation comme base pour l'explanation
        """
        announcement = ", ".join(parties) if parties else "Votre silhouette"

        # Base explanation
        explanation = silhouette_explanation or "Certaines zones peuvent √™tre visuellement att√©nu√©es par des coupes et volumes mieux plac√©s."

        # Enrichir avec les sources
        if onboarding_parties and openai_parties:
            explanation += (
                f"\n\nCette analyse combine vos pr√©f√©rences (vous aviez s√©lectionn√©: {', '.join(onboarding_parties)}) "
                f"avec nos recommandations morphologiques (nous sugg√©rons: {', '.join(openai_parties)})."
            )
        elif onboarding_parties:
            explanation += f"\n\nVous aviez s√©lectionn√© ces zones √† minimiser: {', '.join(onboarding_parties)}."
        elif openai_parties:
            explanation += f"\n\nNous recommandons de minimiser visuellement: {', '.join(openai_parties)}."

        full_text = f"""ANNONCE: {announcement}

EXPLICATION: {explanation}"""

        return {
            "announcement": announcement,
            "explanation": explanation,
            "full_text": full_text
        }

    @staticmethod
    def _repair_broken_json(json_str: str) -> str:
        """R√©pare les JSON partiellement cass√©s (best-effort)."""
        if not isinstance(json_str, str):
            return ""

        # Enlever guillemets typographiques
        json_str = json_str.replace("‚Äú", '"').replace("‚Äù", '"').replace("‚Äô", "'")

        # Supprimer virgules finales avant } ou ]
        json_str = re.sub(r",\s*([}\]])", r"\1", json_str)

        # Fermer accolades manquantes
        open_count = json_str.count("{")
        close_count = json_str.count("}")
        if open_count > close_count:
            json_str += "}" * (open_count - close_count)

        open_count = json_str.count("[")
        close_count = json_str.count("]")
        if open_count > close_count:
            json_str += "]" * (open_count - close_count)

        return json_str

    
async def force_valid_json(self, raw_content: str, context: str) -> dict:
    """
    Redemande √† OpenAI de corriger STRICTEMENT un JSON invalide.
    Version durcie: nettoyage + extraction + r√©paration locale + truncate anti-OVER.
    """
    def _extract_main_json_block(s: str) -> str:
        if not isinstance(s, str) or not s.strip():
            return ""
        s = self.clean_json_string(s)
        start = s.find("{")
        end = s.rfind("}") + 1
        if start != -1 and end > start:
            return s[start:end]
        return s

    def _log_json_error(prefix: str, err: Exception, payload: str):
        if not isinstance(payload, str):
            payload = str(payload)
        if isinstance(err, json.JSONDecodeError):
            pos = err.pos
            excerpt = payload[max(0, pos - 120): pos + 120]
            print(f"   ‚ùå {prefix} JSONDecodeError: line={err.lineno} col={err.colno} pos={err.pos}")
            print(f"   üîé Extrait autour erreur: {excerpt}")
        else:
            print(f"   ‚ùå {prefix} error: {str(err)}")

    def _truncate_for_fix(s: str, max_chars: int = 6000) -> str:
        """
        Emp√™che le prompt de r√©paration de d√©passer le budget.
        On conserve d√©but + fin, ce qui garde souvent la structure.
        """
        if not isinstance(s, str):
            return ""
        s = s.strip()
        if len(s) <= max_chars:
            return s
        head = s[: int(max_chars * 0.55)]
        tail = s[-int(max_chars * 0.45):]
        return head + "\n...\n" + tail

    # 1) Extraction bloc JSON
    cleaned = _extract_main_json_block(raw_content)

    # 2) Sanitize retours ligne DANS les strings (ton helper)
    if hasattr(self, "sanitize_json_multiline_strings"):
        cleaned = self.sanitize_json_multiline_strings(cleaned)

    # 3) R√©paration locale best-effort
    cleaned = self._repair_broken_json(cleaned)

    # 4) Tentative parsing local
    try:
        return json.loads(cleaned)
    except Exception as e:
        _log_json_error("Local-parse", e, cleaned)

    # 5) Si c‚Äôest trop gros, on tronque AVANT d‚Äôenvoyer au fixeur
    cleaned_for_fix = _truncate_for_fix(cleaned, max_chars=6000)

    repair_prompt = f"""
        Tu vas recevoir un JSON invalide. Tu dois renvoyer UNIQUEMENT un JSON strict valide.

        R√®gles:
        - R√©ponds uniquement par un objet JSON qui commence par {{ et se termine par }}.
        - Aucun texte avant ou apr√®s. Aucun Markdown. Aucun ```json.
        - Guillemets doubles uniquement.
        - Aucune virgule finale.
        - Si une valeur contient des retours √† la ligne, remplace-les par un espace.
        - Conserve exactement la structure et les cl√©s, ne supprime pas de sections.

        JSON √Ä CORRIGER:
        {cleaned_for_fix}
        """.strip()

    self.openai.set_context(f"{context} - JSON FIX", "")
    self.openai.set_system_prompt(
        "Tu es un validateur JSON strict. Tu renvoies uniquement un JSON strict valide, sans Markdown, sans commentaire."
    )

    response = await self.openai.call_chat(
        prompt=repair_prompt,
        model="gpt-4-turbo",
        max_tokens=1200
    )

    content = (response.get("content", "") or "").strip()
    content = _extract_main_json_block(content)

    if hasattr(self, "sanitize_json_multiline_strings"):
        content = self.sanitize_json_multiline_strings(content)

    content = self._repair_broken_json(content)

    try:
        return json.loads(content)
    except Exception as e:
        _log_json_error("OpenAI-fix-parse", e, content)
        raise


    def _generate_default_recommendations(self, silhouette: str) -> dict:
        """G√©n√®re des recommandations par d√©faut si OpenAI √©choue (structure SAFE compl√®te)"""
        print("   ‚úÖ G√©n√©ration recommandations par d√©faut")

        # --- Base fallback minimal mais complet, compatible template + fusion ---
        base_category = lambda label: {
            "introduction": f"Recommandations g√©n√©rales pour les {label}.",
            "recommandes": [
                {
                    "cut_display": "Coupe adapt√©e √† votre silhouette",
                    "why": "Cette coupe aide √† √©quilibrer les volumes et √† structurer la silhouette."
                }
            ],
            "a_eviter": [
                {
                    "cut_display": "Coupe non structur√©e",
                    "why": "Elle peut d√©s√©quilibrer visuellement la silhouette et alourdir la ligne."
                }
            ]
        }

        defaults = {
            "A": {
                "hauts": {
                    "introduction": "Pour une silhouette A, l‚Äôobjectif est de valoriser le haut du corps et d‚Äôapporter de la structure aux √©paules.",
                    "recommandes": [
                        {"cut_display": "Haut structur√©", "why": "Cr√©e du volume au haut"},
                        {"cut_display": "Encolure V", "why": "Allonge le buste"},
                        {"cut_display": "Col rond ajust√©", "why": "Met en avant les √©paules"},
                        {"cut_display": "Haut √©chancr√©", "why": "Cr√©e de la profondeur"},
                        {"cut_display": "Manches montantes", "why": "D√©finit les √©paules"},
                        {"cut_display": "Peplum plac√© haut", "why": "Donne du relief au haut du corps"},
                    ],
                    "a_eviter": [
                        {"cut_display": "Haut moulant long", "why": "Accentue le contraste haut/bas"},
                        {"cut_display": "Tunique informe", "why": "Retire la structure du buste"},
                        {"cut_display": "Col bateau tr√®s large", "why": "√âlargit artificiellement"},
                        {"cut_display": "Haut oversize sans taille", "why": "Perd les proportions"},
                        {"cut_display": "Manches tr√®s bouffantes", "why": "Peut surcharger le haut"},
                    ]
                },
                "bas": {
                    "introduction": "Pour une silhouette A, l‚Äôobjectif est d‚Äôallonger la jambe et d‚Äô√©quilibrer la zone des hanches.",
                    "recommandes": [
                        {"cut_display": "Jean taille haute droit", "why": "Allonge les jambes"},
                        {"cut_display": "Pantalon droit", "why": "√âquilibre les hanches"},
                        {"cut_display": "Jupe √©vas√©e", "why": "Harmonise la ligne des hanches"},
                        {"cut_display": "Pantalon flare l√©ger", "why": "Cr√©e une verticalit√©"},
                        {"cut_display": "Jupe pliss√©e fine", "why": "Structure sans √©paissir"},
                        {"cut_display": "Couleurs plus sombres en bas", "why": "Affinent visuellement"},
                    ],
                    "a_eviter": [
                        {"cut_display": "Pantalon moulant clair", "why": "Met l‚Äôaccent sur les hanches"},
                        {"cut_display": "Short tr√®s court", "why": "Raccourcit la jambe"},
                        {"cut_display": "Pantalon tr√®s large", "why": "√âlargit la silhouette"},
                        {"cut_display": "Jupe portefeuille √©paisse", "why": "Ajoute du volume lat√©ral"},
                        {"cut_display": "Motifs larges sur les hanches", "why": "Grossissent visuellement"},
                    ]
                },
                "robes": base_category("robes"),
                "vestes": base_category("vestes"),
                "maillot_lingerie": base_category("maillots / lingerie"),
                "chaussures": base_category("chaussures"),
                "accessoires": base_category("accessoires"),
            }
        }

        # Si silhouette inconnue ‚Üí fallback sur A
        result = defaults.get(silhouette, defaults["A"])

        # S√©curit√© : s‚Äôassurer que toutes les cat√©gories existent
        for category in ["hauts", "bas", "robes", "vestes", "maillot_lingerie", "chaussures", "accessoires"]:
            if category not in result:
                result[category] = base_category(category)

            # S√©curit√© : cl√©s attendues
            result[category].setdefault("introduction", "")
            result[category].setdefault("recommandes", [])
            result[category].setdefault("a_eviter", [])

        return {"recommendations": result}


morphology_service = MorphologyService()